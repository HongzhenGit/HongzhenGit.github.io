<!doctype html>
<html lang="en">
  <head>
  <script src="https://use.fontawesome.com/baff6f55f5.js"></script>
    <meta charset="utf-8">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <title>Hongzhen's Personal Website</title>

    <link rel="stylesheet" href="stylesheets/styles.css">
    <link rel="stylesheet" href="stylesheets/github-light.css">
    <meta name="viewport" content="width=device-width, initial-scale=1, user-scalable=yes">
    <!--[if lt IE 9]>
    <script src="//html5shiv.googlecode.com/svn/trunk/html5.js"></script>
    <![endif]-->

    <script>
      (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
      (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
      m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
      })(window,document,'script','https://www.google-analytics.com/analytics.js','ga');

      ga('create', 'UA-29643011-3', 'auto');
      ga('send', 'pageview');
    </script>

    <!-- New GA4 tracking code, see https://support.google.com/analytics/answer/10271001#analyticsjs-enable-basic --> 
    <script async src="https://www.googletagmanager.com/gtag/js?id=G-GNJD50R0Z7"></script>
    <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());
    gtag('config', 'G-GNJD50R0Z7');
    </script>

    <!-- For all browsers -->
    <link rel="stylesheet" href="assets/css/academicons.min.css"/>
    <link rel="stylesheet" href="assets/css/academicons.css"/>
    
    <style>
      button.accordion {
      font:14px/1.5 Lato, "Helvetica Neue", Helvetica, Arial, sans-serif;
      cursor: pointer;
      padding: 0px;
      border: none;
      text-align: left;
      outline: none;
      font-size: 100%;
      transition: 0.3s;
      background-color: #f8f8f8;
      }
      button.accordion.active, button.accordion:hover {
      background-color: #f8f8f8;
      }
      button.accordion:after {
      content: " [+] ";
      font-size: 90%;
      color:#777;
      float: left;
      margin-left: 1px;
      }

      button.accordion.active:after {
      content: " [\2212] ";
      }
      div.panel {
      padding: 0 20px;
      margin-top: 5px;
      display: none;
      background-color: white;
      font-size: 100%;
      }
      div.panel.show {
      display: block !important;
      }
      .social-row {
        display: flex;
        flex-wrap: wrap;
        justify-content: space-between;
      }
    </style>
  </head>
  <body>
    <div class="wrapper">
      <header>
        <h1>ZHANG, Hongzhen</h1>
        <p>Senior Data Analyst<br>Discover Financial Service</p>
        <p>Postgraduate University<br><a href="http://www.tju.edu.cn/english/index.htm">Tianjin University(TJU)</a></p>
        <p>Undergraduate University<br><a href="https://en.xmu.edu.cn/">Xiamen University(XMU)</a></p>
        <h3><a href="https://hongzhengit.github.io/">About Me</a></h3>
        <h3><a href="https://hongzhengit.github.io/research.html">Research</a></h3>
        <h3><a href="https://hongzhengit.github.io/research/Zhanghongzhen_Academic CV.pdf">CV/Resume</a></h3>  
        <!--<h3><a href="https://hongzhengit.github.io/code.html">Project Reporsitory</a></h3>--> 
        <h3><a href="https://hongzhengit.github.io/working.html">Working Experience</a></h3> 
        <h3><a href="https://hongzhengit.github.io/awards.html">Awards</a></h3>
    <b>Social</b><br>
        <div class="social-row">
          <!--<a href="https://scholar.google.com/..." target="_blank"><i class="ai ai-fw ai-google-scholar-square"></i> Scholar</a><br>-->
          <!--<a href="https://orcid.org/..."><i class="ai ai-fw ai-orcid-square"></i> ORCID</a><br>-->
          <!--<a href="http://ideas.repec.org/..."><i class="fa fa-fw fa-share-alt-square"></i> RePEc</a><br>-->
          <a href="https://github.com/HongzhenGit"><i class="fa fa-fw fa-github-square"></i> GitHub</a><br>
          <!--<a href="http://twitter.com/..." class="author-social" target="_blank"><i class="fa fa-fw fa-twitter-square"></i> Twitter</a><br>-->
          <a href="https://www.linkedin.com/in/hongzhen-zhang-2a8126193/" class="author-social" target="_blank"><i class="fa fa-fw fa-linkedin-square"></i> LinkedIn</a><br>
          <br>
        </div>
        <br>

    <p><b>Contact Information:</b><br>Email: zhanghongzhen1019@outlook.com<br>Phone Number: 86-18765801028</p>
    <p><small>Hosted on GitHub Pages &mdash; Theme by <a href="https://github.com/orderedlist">orderedlist</a></small></p>

      </header>
      <section>
      <!-- <h2>Teaching Statement</h2> -->
      <!-- <p><a href="https://tyleransom.github.io/teaching/Teaching-Statement.pdf">Download (PDF)</a><br></p> -->
      
      <h2>Working Experience</h2>
      <!--<p><a href="https://tyleransom.github.io/teaching/EvalsSummary.pdf">Overall Summary of Teaching Evaluations</a></p>-->
      <p>Here lists some key peoject experiences of mine</a></p>
     
      <hr>
      <!--<h3>Instructor and Designer</h3>-->
      <h4><b>Volume Forecast for Home Loan Applications(DFS, 02.2022 - 05.2022)</b></h4>
      This project is proposed mainly becasue the house price in USA jumped by 18% last year. This significant increase in house price brings a boost of $3.2 trillion in home equity, 
      which contributed a lot to the momentum for home equity loan applications. As a consequence, DFS need hire more stuffs to help on these extra applications. To provide some insights, we built a 
      time series model with Prophet (Developed by Meta Open Source) and used it to make predictions on future application volumes. With predicted volumes, an approximated 
      number of newly hired agents could be estimated.<br>
      Here is another similar but simpler time series forecast project developed with Prophet by me(<a href="https://github.com/HongzhenGit/Time-Series-Forecasting">Forecast on electricity demand in AUS</a>)<br>
      <!--<ul>
       <li>Data preparation and pre-processing(resample the data, fill up null values, remove outliers).</li>
       <li>Correlation anlysis to get the extra regressors that may help improve the model explanation capability.</li>
       <li>Model training and validation based on Prophet Package(Developed by Meta Open Source).</li>
       <li>Make predictions on future volumes and estimate the number of agents that need to be hired.</li>
       <li>Here is a similar and simpler project based on public dataset(<a href="https://github.com/HongzhenGit/Time-Series-Forecasting">Forecast on electricity demand in AUS</a>)</li>
       <!--<li><a href="https://tyleransom.github.io/research/TenPrinciplesOfEconOfEd.pdf">10 Principles of the Economics of Education</a></li>
      </ul>-->
      <br>
      <h4><b>NLP research on Customers Complaints(DFS, 03.2021 - 07.2021)</b></h4>
      With the continuous increase in market share that DFS products possess, lots of text comments(or voice transcripts) are received by our agents, which include feedbacks 
      and customer complaints. It is hard to review these text materials manually, so an automated document analysis tool is necessary to help on the analytic and classification tasks. We constructed 
      a binary classifer with pre-trained BERT to recognize complaints from a large set of texts, and then took advantage of a Random Forest classifier to divide these complaints into a set of 
      determined categories. For non-labeled complaints, the Spherical k-Means Clustering algorithm was leveraged to analyse their natrual clusters, combined with a Community Detection(Louvain Method) method
      to extract topics.<br>
      Here is another similar but simpler classifier project developed with pre-trained BERT by me(<a href="https://github.com/HongzhenGit/NLP-Research">One VS Rest Document Classifier</a>)<br>
      <!--<ul>
       <li>Text preprocessing(Remove punctuations and stopwords, Word Steming or Lemmatization..)  </li>
       <li>Build a binary classifier based on BERT to detect complaints</li>
       <li>Construct a Random Forest(RF) model for complaint categorization</li>
       <li>Analyse non-labeled complaints with Community Detection Technology(Network Analysis)</li> 
       <li>Here is a similar and simpler project based on public dataset(<a href="https://github.com/HongzhenGit/NLP-Research">One VS Rest Document Classifier</a>)</li> 
      </ul>-->
      <br>
      <h4><b>Parameter Selection for Generalized Memory Polynomial(GMP) Model(ADI, 07.2019 - 01.2020)</b></h4>
      Generalized Memory Polynomial (GMP) Model is a widely-used compensation structure for linearity in Digital Pre-Distortion (DPD). However, DPD is working on the frequency domain 
      and the signal data used to build GMP model are complex numbers. Our target was to simplify the form of GMP model and then reduce the circuit scale of DPD. We did research into 
      the gradient descent and Gauss-Newton method in complex domain to help us estimate the parameters of a standard GMP model, and leveraged the c-Lasso algorithm mentioned in 
      <a href="https://doi.org/10.1121/1.5042363 ">Muhammad Tabassum and Esa Ollila</a> to get a simplified GMP model with sparse parameters.<br>
      <!--Generalized Memory Polynomial(GMP) Model is a widely-used compensation structure in Digital Pre-Distortion. To get a desirable improvment in linearity, a GMP model could be very complex,
      which requires a circuit with large scale. To reduce cost and simplify the structure of DPD, a good solution is to only keep those featrues that have significant impact on the compensation. 
      However, DPD is working on the frequency domain and the signal data used to build GMP model are complex numbers. To deal with these issues, We did research into the gradient descent and 
      Gauss-Newton method in complex domain to help us estimate the parameters of a standard GMP model, 
      and applied the c-Lasso algorithm mentiond in <a href="https://doi.org/10.1121/1.5042363 ">Muhammad Tabassum and Esa Ollila</a> to get a sparse version of GMP model.<br>-->
      <!--<ul>
       <li>Gradient Descent and Gauss-Newton Method in the complex domain</li>
       <li>LASSO regression in the complex domain</li>
       <li>Research on LASSO solution path</li>
       <li>A reference for complex lasso(<a href="https://doi.org/10.1121/1.5042363 ">Muhammad Naveed Tabassum and Esa Ollila</a>)</li>
      </ul>-->
      <br>
      <hr>
      <!--<hr />-->
      <h3 style="margin-top:2px margin-bottom:6px">Other Projects</h3>
      <h4 style="margin-top:6px">Data Management Platform developed with PyQt(DFS, 08.2020 - 01.2021)</h4>
      This is a desktop application developed with PyQt to maintain the invoice data from third party vendors. We built the connections between our app and data warehouses(Teradata, Snowflake, MySQL..).
      With these connections, our application could structure the data from vendors and upload them onto our data warehouses automatically. Besides, some visualization reports were also constructed to track the 
      performance of thrid party costs.
      <!--<ul>
        <li>Developed a desktop application based on PyQt</li>
        <li>Build the connection between app and data warehouse(Teradata, Snowflake, MySQL..)</li>
        <li>Automatically structrue the data from vendors and upload them onto data warehouse</li>
        <li>Construct visualization reports to track the cost performance of vendors</li>
      </ul>   
      <hr />-->  
      </section>
    </div>
    <script src="javascripts/scale.fix.js"></script>
  </body>
</html>
